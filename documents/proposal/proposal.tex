\documentclass[12pt]{article}

% This first part of the file is called the PREAMBLE. It includes
% customizations and command definitions. The preamble is everything
% between \documentclass and \begin{document}.

\usepackage[margin=1in]{geometry}  % set the margins to 1in on all sides
\usepackage{graphicx}              % to include figures
\usepackage{epstopdf}
\usepackage{amsmath}               % great math stuff
\usepackage{amsfonts}              % for blackboard bold, etc
\usepackage{amsthm}                % better theorem environments




\begin{document}

\begin{center}
{\bf \Large Visual Saliency: A Project Proposal}  \\
\vspace{.1in}
{\em Shupei Zhang}
\end{center}
%\setlength\parindent{0pt}
\section{Introduction}
Visual saliency is the different extent of attraction of different objects to our visual system. Human visual system
is developed to focus on the most salient stimuli and pay less attention to the rest. A reason for developing such a 
feature is that the amount of data we receive through our eyes exceeds our ability to process data. 
The human retina has approximately 6 million cones and 120 million rods\cite{PhotoreceptorCell2021}, which are responsible for color vision 
and night vision, respectively. Such huge amount of photoreceptors generates huge amount of data, and it is a big challenge for our brain to 
process it efficiently.
Visual saliency helps us identify the most imminent threat, danger, or events needing our attention in general. Therefore it reduces 
the load in our visual system.

Study visual saliency can help us have a deeper understanding of human visual system. This can lead to many applications, such as
image/video segmentation, image/video compression, foreground annotation, perceptual quality assesment etc\cite{congReviewVisualSaliency2019}.
For example, all the current video coding methods are block-based compression. Spacial redundancy is reduced through intra-frame coding and temporal 
redundancy is reduced through inter-frame coding\cite{sullivanOverviewHighEfficiency2012}. With visual saliency information, encoders can further increase
the compression ratio by decreasing the quality of regions of low intrest, for example, the background. Because it is hard for us to notice the changes in those regions,
the perceptual visual quality will likely remain the same. Moreover, visual saliency study might help game developers in optimizing the performance 
of their games. Due to the difference in attraction of different regions, not all regions need to be rendered in the highest quality.
This can help games achieve better graphics performance. Therefore, we think it is important to do some research in this area.
\section{Related Work}
Visual saliency detection methods can be categorized into two two classes: bottom-up models and top-down models\cite{congReviewVisualSaliency2019}.
Before deep learning was widely applied in this field, most of the early methods are bottom-up models.
Those early methods usually involve biological and psychological research about visual attention mechanism. And those two approaches match the common beliefs about biological process of human vision.
In general, those models try to establish links between visual saliency and low-level image features, such as color, contrast, brightness etc. The Itti. model\cite{ittiModelSaliencybasedVisual1998}
is one of the earliest model of this kind, which predicts visual saliency from linear combination of features calculated from color, intensity and orientation.
Some other techniques are also used to achieve better results, such as frequency domain analysis, sparse representation, cellular automata etc\cite{congReviewVisualSaliency2019}.

Top-down models, in the other hand, try to find what factors have the most impact on visual saliency. Those models use visual saliency data, and analyze them in a data-driven fashion.
In recent years, deep learning is introduced into this area and has boosted the performance of saliency prediction a lot.
Vig et al. \cite{vigLargeScaleOptimizationHierarchical2014} proposed the first neural network for saliency prediction, combining CNN and SVM. Later, researchers start to use transfer learning for saliency 
detection tasks. VGG is used in multiple models\cite{kruthiventiDeepFixFullyConvolutional2015, kummererDeepGazeIIReading2016, corniaPredictingHumanEye2018}, and some of them incorporate gaussian prior for performance improvement.
Generative adversarial networks also achieve good results in saliency prediction\cite{panSalGANVisualSaliency2018, cheHowGazeInfluenced2020}.

Attention mechanisms were first applied in natural language processing (NLP) models for their ability to model long range and multi-level information\cite{bahdanauNeuralMachineTranslation2016a, vaswaniAttentionAllYou2017a}.
They are later introduced for computer vision tasks and show strong potential in modeling non-local dependencies in images\cite{zhangSelfAttentionGenerativeAdversarial2019a}.
But this technique has not been applied in visual saliency tasks so far.
\newpage

\bibliographystyle{plain}

\bibliography{reading_assigment1}


\end{document}
